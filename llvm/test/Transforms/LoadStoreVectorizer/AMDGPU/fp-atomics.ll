; NOTE: Assertions have been autogenerated by utils/update_test_checks.py UTC_ARGS: --version 5
; RUN: opt -passes=load-store-vectorizer -S < %s | FileCheck %s

; Test atomicrmw fadd with <2 x half> data type.
define amdgpu_kernel void @func1(ptr addrspace(3) %ptr, <2 x half> %data) #0 {
; CHECK-LABEL: define amdgpu_kernel void @func1(
; CHECK-SAME: ptr addrspace(3) [[PTR:%.*]], <2 x half> [[DATA:%.*]]) {
; CHECK-NEXT:    [[FUNC1_KERNARG_SEGMENT:%.*]] = call nonnull align 16 dereferenceable(264) ptr addrspace(4) @llvm.amdgcn.kernarg.segment.ptr()
; CHECK-NEXT:    [[PTR_KERNARG_OFFSET1:%.*]] = bitcast ptr addrspace(4) [[FUNC1_KERNARG_SEGMENT]] to ptr addrspace(4)
; CHECK-NEXT:    [[TMP1:%.*]] = load <2 x i32>, ptr addrspace(4) [[PTR_KERNARG_OFFSET1]], align 16
; CHECK-NEXT:    [[PTR_LOAD1:%.*]] = extractelement <2 x i32> [[TMP1]], i32 0
; CHECK-NEXT:    [[DATA_LOAD2:%.*]] = extractelement <2 x i32> [[TMP1]], i32 1
; CHECK-NEXT:    [[FOO1_BITCAST:%.*]] = bitcast i32 [[DATA_LOAD2]] to <2 x half>
; CHECK-NEXT:    [[FOO1_INTTOPTR:%.*]] = inttoptr i32 [[PTR_LOAD1]] to ptr addrspace(3)
; CHECK-NEXT:    [[I1:%.*]] = atomicrmw fadd ptr addrspace(3) [[FOO1_INTTOPTR]], <2 x half> [[FOO1_BITCAST]] syncscope("agent") seq_cst, align 4
; CHECK-NEXT:    ret void
;
  %func1.kernarg.segment = call nonnull align 16 dereferenceable(264) ptr addrspace(4) @llvm.amdgcn.kernarg.segment.ptr()
  %ptr.kernarg.offset1 = bitcast ptr addrspace(4) %func1.kernarg.segment to ptr addrspace(4)
  %ptr.load = load ptr addrspace(3), ptr addrspace(4) %ptr.kernarg.offset1, align 16
  %data.kernarg.offset = getelementptr inbounds i8, ptr addrspace(4) %func1.kernarg.segment, i64 4
  %data.load = load <2 x half>, ptr addrspace(4) %data.kernarg.offset, align 4
  %i1 = atomicrmw fadd ptr addrspace(3) %ptr.load, <2 x half> %data.load syncscope("agent") seq_cst, align 4
  ret void
}

; Test atomicrmw fadd with <2 x half> data type and an i32 pointer.
define amdgpu_kernel void @func2(i32 %ptr.as.int, <2 x half> %data) #0 {
; CHECK-LABEL: define amdgpu_kernel void @func2(
; CHECK-SAME: i32 [[PTR_AS_INT:%.*]], <2 x half> [[DATA:%.*]]) {
; CHECK-NEXT:    [[FUNC2_KERNARG_SEGMENT:%.*]] = call nonnull align 16 dereferenceable(264) ptr addrspace(4) @llvm.amdgcn.kernarg.segment.ptr()
; CHECK-NEXT:    [[PTR_AS_INT_KERNARG_OFFSET1:%.*]] = bitcast ptr addrspace(4) [[FUNC2_KERNARG_SEGMENT]] to ptr addrspace(4)
; CHECK-NEXT:    [[TMP1:%.*]] = load <2 x i32>, ptr addrspace(4) [[PTR_AS_INT_KERNARG_OFFSET1]], align 16
; CHECK-NEXT:    [[PTR_AS_INT_LOAD:%.*]] = extractelement <2 x i32> [[TMP1]], i32 0
; CHECK-NEXT:    [[DATA_LOAD2:%.*]] = extractelement <2 x i32> [[TMP1]], i32 1
; CHECK-NEXT:    [[PTR:%.*]] = inttoptr i32 [[PTR_AS_INT_LOAD]] to ptr addrspace(3)
; CHECK-NEXT:    [[DATA_LOAD_BITCAST:%.*]] = bitcast i32 [[DATA_LOAD2]] to <2 x half>
; CHECK-NEXT:    [[PTR_AS_INT_LOAD_INTTOPTR:%.*]] = inttoptr i32 [[PTR_AS_INT_LOAD]] to ptr addrspace(3)
; CHECK-NEXT:    [[I1:%.*]] = atomicrmw fadd ptr addrspace(3) [[PTR_AS_INT_LOAD_INTTOPTR]], <2 x half> [[DATA_LOAD_BITCAST]] syncscope("agent") seq_cst, align 4
; CHECK-NEXT:    ret void
;
  %func2.kernarg.segment = call nonnull align 16 dereferenceable(264) ptr addrspace(4) @llvm.amdgcn.kernarg.segment.ptr()
  %ptr.as.int.kernarg.offset1 = bitcast ptr addrspace(4) %func2.kernarg.segment to ptr addrspace(4)
  %ptr.as.int.load = load i32, ptr addrspace(4) %ptr.as.int.kernarg.offset1, align 16
  %data.kernarg.offset = getelementptr inbounds i8, ptr addrspace(4) %func2.kernarg.segment, i64 4
  %data.load = load <2 x half>, ptr addrspace(4) %data.kernarg.offset, align 4
  %ptr = inttoptr i32 %ptr.as.int.load to ptr addrspace(3)
  %i1 = atomicrmw fadd ptr addrspace(3) %ptr, <2 x half> %data.load syncscope("agent") seq_cst, align 4
  ret void
}
